{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to use `AdversarialAttackEvaluator` to evaluate the performence of adversarial attacks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import advsecurenet.shared.types.configs.attack_configs as AttackConfigs\n",
    "\n",
    "from advsecurenet.models.model_factory import ModelFactory\n",
    "from advsecurenet.datasets import DatasetFactory\n",
    "from advsecurenet.dataloader import DataLoaderFactory\n",
    "from advsecurenet.attacks import PGD, CWAttack, FGSM, LOTS, DeepFool\n",
    "from advsecurenet.shared.types import DatasetType, ModelType\n",
    "from advsecurenet.utils.model_utils import load_model, download_weights\n",
    "from advsecurenet.utils.evaluation import AdversarialAttackEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first download the weights\n",
    "download_weights(filename=\"CustomMnistModel_mnist_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model\n",
    "model = ModelFactory.create_model('CustomMnistModel', num_classes=10, num_channels=1) # this assumes that the CustomMnistModel is defined in the models/CustomMnistModel.py file\n",
    "model = load_model(model, 'CustomMnistModel_mnist_weights.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataset\n",
    "dataset_obj =DatasetFactory.create_dataset(DatasetType.MNIST)\n",
    "#trainData = datasetObj.load_dataset(train=True)\n",
    "test_data = dataset_obj.load_dataset(train=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_loader = DataLoaderFactory.create_dataloader(test_data,batch_size=32, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = AdversarialAttackEvaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fgsm_config = AttackConfigs.FgsmAttackConfig(\n",
    "    epsilon=0.05\n",
    ")\n",
    "fgsm = FGSM(fgsm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "experiment_info = {\n",
    "    \"model_name\": \"CustomMnistModel\",\n",
    "    \"dataset_name\": \"MNIST\",\n",
    "    \"attack_name\": \"FGSM\",\n",
    "    \"is_targeted\": False,\n",
    "    \"researcher\": \"Melih Catal\"\n",
    "} \n",
    "file_name = \"results.csv\"\n",
    "for images, labels in test_data_loader:\n",
    "    adv_img = fgsm.attack(model, images, labels)\n",
    "    results = evaluator.full_evaluation(model, original_images=images, true_labels=labels, adversarial_images=adv_img, is_targeted=False)\n",
    "    evaluator.save_results_to_csv(results, experiment_info, file_name=file_name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.evaluate_attack(model, images, labels, adv_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.calculate_perturbation_distances(images, adv_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.calculate_robustness_gap(model, images, labels, adv_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.calculate_ssim(images, adv_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.calculate_similarity_scores(images, adv_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_model = ModelFactory.create_model(\"CustomMnistModel\", num_classes=10, num_channels=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.calculate_transferability_rate(source_model=model, target_model=target_model, original_images=images, true_labels=labels, adversarial_images=adv_img, is_targeted=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = evaluator.full_evaluation(model, original_images=images, true_labels=labels, adversarial_images=adv_img, is_targeted=False)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the results\n",
    "experiment_info = {\n",
    "    \"model_name\": \"CustomMnistModel\",\n",
    "    \"dataset_name\": \"MNIST\",\n",
    "    \"attack_name\": \"FGSM\",\n",
    "    \"is_targeted\": False,\n",
    "    \"researcher\": \"Melih Catal\"\n",
    "} \n",
    "evaluator.save_results_to_csv(results, experiment_info)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python new",
   "language": "python",
   "name": "new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
